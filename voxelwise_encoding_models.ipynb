{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 490 - Computer Vision \n",
    "# BIOMI 813 - Pattern recognition and machine learning\n",
    "---\n",
    "## Voxelwise encoding models\n",
    "One of the major goal of computational neurosciences is to understand the underlying the algorithms that \"runs\" on the neural substrate: e.g. how are image processed?, i.e. how does the retinal imprint of an object ends up evoking this object in our mind, how are sounds processed?, how do senses interact?, etc. One main avenue of reseach involves the construction of predictive computational models that can predict certain neural observables (e.g. some measure of neural activity, but also more abstract statistical properties). The assumption is that this understanding can be, at least partially, disentangled from the physiological details of the implementation since a model that would predict perfectly brain activity would itself be a working brain.\n",
    "\n",
    "In matters of fact though, we are far from a perfect model of even the simpler sensory processing systems. There are several reasons. First, under the assumption that the brain is a highly nonlinear processing system i.e. that small change in the input may lead to large deviation in the internal state, even if we had a insight into the fundamental algorithm, this would not mean perfect predictions. The reason has to do with the exponential increase of possible states which requires ever finer conditioning whereas our computational ressources are limited. A second reason is that any measurement is intrinsically imprecise, and that living brains *have* to be coupled with a lot of other living systems to remain alive, and that living matter *has* to be coupled with an near-infinite heat bath to remain living. In practice this means that the uncertainty in biological observations is generally several orders of magnitude higher than in physical experiements, albeit intrinsic uncertainties is unavoidable regardless of the type of measurement.\n",
    "\n",
    "Nevertheless, perfection is not required for making prediction of the largest sources of explainable variance in the brain responses to a great variety of stimulus. This is what *encoding* model do, and we have learned a lot about the sensory systems (and continue to) by modelling them. Here is a general picture of how encoding models work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/encoding_model_general_form.png\",width=800, align=center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An encoding model can be divided in two parts. The first part is a *feature extractor* which encompass certain hypotheses we want to test about what the brain does or might represent. It doesn't matter much how the features were optained. The second part is the encoding model itself, which is usually a very shallow-type classifier like your standard run-of-the-mill linear classifier. It is important to find a good feature extractor that capture the observables we are interested in because the type of encoding model is limited by the small number of samples that we can get from real brain. With large number of samples, one could imagine training the feature extractor and encoding model end-to-end, but this often proves impractical.\n",
    "\n",
    "In the following, we show two examples of feature extractor using the same encoding model called the [feature weighted receptive field (fwRF)](http://biorxiv.org/content/early/2017/04/11/126318). The fwRF takes advantage of the spatial structure of certain feature extractor to generate a smaller set of hypothesis, thereby improving the ability of the encoding model to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/gabor_vs_refnet_fwrf_method.png\",width=800, align=center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a deep neural network trained to recognize a vast ensemble of object categories is used for the feature extractor, the ensuing fwRF model tuning reveals an alignment of the visual cortex sensory areas of the brain (a.k.a. regions of interest or ROIs) with the depth of the feature map layer in the network. Here, the network has eight layers: five convolutional layer (conv1-5) followed by three fully connected layers (fc6-8). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/refnet_layer_roi_connections_b.png\",width=800, align=center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
