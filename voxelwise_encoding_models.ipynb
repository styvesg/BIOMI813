{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the brain see? \n",
    "### CSCI 490 - Computer Vision \n",
    "### BIOMI 813 - Pattern recognition and machine learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brains vs. networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/BIOMI_813_Spring_2017_44.png\",width=800, align=center>\n",
    "**Really rough sketch of the visual system** Your eyes sends projections to the back of you brain. There a series of visual areas called \"V1\", \"V2\", and so on encoded features of the image you are seeing. What are those features? How do they compare to the feature we designed or learned when building image classifiers? What we know suggests they may be quite similar. We'll review some of the evidence for the that in this lecture.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Voxelwise encoding models: how we tell what the brain is encoding\n",
    "One of the major goal of computational neurosciences is to understand the underlying the algorithms that \"runs\" on the neural substrate: e.g. how are image processed?, i.e. how does the retinal imprint of an object ends up evoking this object in our mind, how are sounds processed?, how do senses interact?, etc. One main avenue of reseach involves the construction of predictive computational models that can predict certain neural observables (e.g. some measure of neural activity, but also more abstract statistical properties). The assumption is that this understanding can be, at least partially, disentangled from the physiological details of the implementation since a model that would predict perfectly brain activity would itself be a working brain.\n",
    "\n",
    "In matters of fact though, we are far from a perfect model of even the simpler sensory processing systems. There are several reasons. First, under the assumption that the brain is a highly nonlinear processing system i.e. that small change in the input may lead to large deviation in the internal state, even if we had a insight into the fundamental algorithm, this would not mean perfect predictions. The reason has to do with the exponential increase of possible states which requires ever finer conditioning whereas our computational ressources are limited. A second reason is that any measurement is intrinsically imprecise, and that living brains *have* to be coupled with a lot of other living systems to remain alive, and that living matter *has* to be coupled with an near-infinite heat bath to remain living. In practice this means that the uncertainty in biological observations is generally several orders of magnitude higher than in physical experiements, albeit intrinsic uncertainties is unavoidable regardless of the type of measurement.\n",
    "\n",
    "Nevertheless, perfection is not required for making prediction of the largest sources of explainable variance in the brain responses to a great variety of stimulus. This is what *encoding* model do, and we have learned a lot about the sensory systems (and continue to) by modelling them. Here is a general picture of how encoding models work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/encoding_model_general_form.png\",width=800, align=center>\n",
    "\n",
    "**General form of voxel-wise encoding models.** The feature extractor is anything that produce hypothesis about what the voxel observables may represent. These features are generally shared between all voxel encoding models. The voxel encoding models determine which features, or type of features, are most *tuned* to the voxel activity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An encoding model can be divided in two parts. The first part is a *feature extractor* which encompass certain hypotheses we want to test about what the brain does or might represent. It doesn't matter much how the features were optained. The second part is the encoding model itself, which is usually a very shallow-type classifier like your standard run-of-the-mill linear classifier. It is important to find a good feature extractor that capture the observables we are interested in because the type of encoding model is limited by the small number of samples that we can get from real brain. With large number of samples, one could imagine training the feature extractor and encoding model end-to-end, but this often proves impractical.\n",
    "\n",
    "In the following, we show two examples of feature extractor using the same encoding model called the [feature weighted receptive field (fwRF)](http://biorxiv.org/content/early/2017/04/11/126318). The fwRF takes advantage of the spatial structure of certain feature extractor to generate a smaller set of hypothesis, thereby improving the ability of the encoding model to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The features learned by a deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/VanGervnDNN.large.jpg\",width=800, align=center>\n",
    "\n",
    "**A deep convolutional neural network for label objects in an image.** This is a picture in *Guclu and VanGerven, 2016*, which was adapted from the original study by *Krizhevsky et al., 2012* in which this network was designed. The DNN uses several stages of convolutional and max-pooling layers and a few fully-connected layers to classify 1000 objects.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/VanGervenFeatures.large.jpg\",width=800, align=center>\n",
    "\n",
    "**Features learned by the DNN.** A visualization of the features at various layers. At the bottom layer we have edge-like filters. In the top layers we have object representations. In between it is harder to describe what is going on.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features learned by the brain: low-level visual cortex encodes something like a Gabor wavelet transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/nature06713-f1.2.jpg\",width=800, align=center>\n",
    "\n",
    "**Figure from *Kay et al., 2008* showing a Gabor wavelet model for single voxels.** The model was used to perform image identification as a way of testing the accuracy of the model. We found that using brain activity patterns in low-level visual cortex it was possible to discriminate the image that evoked the brain activity from many millions of other images pulled from the internet.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/Neuron_recons.jpg\",width=800, align=center>\n",
    "\n",
    "**Reconstructing images using the Gabor model.** We could also use the model to make these crude reconstructions of what people were looking at. This is a step towards mind-reading, but it isn't really mind-reading.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features learned by the brain: high-level visual cortex encodes explicit information about objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/nihms366884f2.jpg\",width=800, align=center>\n",
    "\n",
    "**An encoding model that uses labeled objects to predict brain activity.** This is from Naselaris et al., 2013. Instead of filtering the image, we assigned all of the objects in the image to one of ~10 categories. Thus each image was mapped to a binary pattern that labeled the objects in it. We found that this did a really good job of predicting brain activity in high-level cortex, but not in low level cortex. Weirdly, we found that in most voxels, activity is really sensitive to whether the object is alive or not alive.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/nihms366884f4.jpg\",width=800, align=center>\n",
    "\n",
    "**Decoding the contents of images from brain activity.** We used the same trick as with the Gabor model to decode the all the objects (or at least their categories) from images that peopled looked at as we scanned their brain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features learned by the brain: what's going on in the middle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/gabor_vs_refnet_fwrf_method.png\",width=800, align=center>\n",
    "\n",
    "**The feature-weighted receptive field (fwRF) model.** A) The fwRF model takes advantage of the spatial organization of convolutional-type *feature maps* to reduce the number of free parameters of the voxel encoding model, thereby allowing for increased expressivity and/or better generalization to new samples. B) Feature maps generated by convolving the stimuli with a Gabor dictionary spanning several spatial frequency and orientations. C) Feature maps generated as the intermediary products of a deep convolutional neural network presented with the stimuli.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a deep neural network trained to recognize a vast ensemble of object categories is used for the feature extractor, the ensuing fwRF model tuning reveals an alignment of the visual cortex sensory areas of the brain (a.k.a. regions of interest or ROIs) with the depth of the feature map layer in the network. Here, the network has eight layers: five convolutional layer (conv1-5) followed by three fully connected layers (fc6-8). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src=\"img/refnet_layer_roi_connections_b.png\",width=800, align=center>\n",
    "\n",
    "**Brain area tuning to a convolutional deep network layers.** Lower layers in the network tune best to areas closer to the retina, suggesting that the represententions that lead to image classification in the network correspond closely to the hierarchy of representations in the visual cortex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "<img src=\"img/gabor_vs_refnet_S1_V3a-V3b-V4-LO-other.png\",width=800, align=center>\n",
    "\n",
    "**Predicting brain activity with the Gabor vs. the Deepnet model.** Those middle layers of the DNN are doing a much better job of predicting activity in intermediate areas than the Gabor wavelets. \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
